====
Payu
====

:subtitle: A climate model workflow manager
:author: Marshall Ward
:description: A Payu training course
:date: 3 October 2018


What is Payu?
=============

Etymology
---------

* *P*\ ython on v\ *AYU*

  Vayu was Raijin's predecessor and has passed away...

  ...but Payu lives on!


Motivation
----------

Long ago, we managed many, many jobscripts.

Many kinds of scripts:
   bash, tcsh, ksh, ...

Many different models:
   MOM, MITgcm, Q-GCM, ACCESS, ...

Juggling and sharing scripts was becoming a problem!


----

.. image:: img/andy_at_nci.png

"Why not just do everything in Python?"


Prehistoric Payu
----------------

.. code:: python

   from payu import gold

   def main():
       expt = gold(forcing='andrew')

       expt.setup()
       expt.run()
       expt.archive()
       if expt.counter < expt.max_counter:
           expt.resubmit()

   if __name__ == '__main__':
       main()


.. remove me

   Setting up
   ==========

   This will initialise your "laboratory"


   Your laboratory
   ===============

   Initialise your "laboratory"::

      payu init -m mom

   What's to be inside?

   * Lab path
   * Archive
   * bin, etc

   (Check: Do we automatically create this?)


Using Payu
==========

Using an experiment
-------------------

Clone an existing experiment (usually in ``$HOME``):

.. code:: sh

   cd $HOME
   mkdir -p mom
   cd mom
   git clone /short/public/mxw900/payucourse/expt/bowl1

This is the "*control directory*" for ``bowl1``


Run the experiment
------------------

Use the system payu::

   module load payu

This job is pre-configured, run it!

.. code:: sh

   cd bowl1
   payu run

* Model will run in ``work/``

* Output saved to ``archive/``


Your experiment
---------------

Your Payu configuration file:

* ``config.yaml``

Your model (MOM) configuration files:

* ``input.nml``

* ``diag_table``

* ``data_table``

* ``field_table``


Experiment Configuration
------------------------

.. code:: yaml

   # PBS
   queue: express
   ncpus: 4
   walltime: 0:10:00
   mem: 1GB
   jobname: bowl1

   # Model
   model: mom
   input: /short/public/mxw900/payucourse/input/bowl1
   exe: /short/public/mxw900/payucourse/bin/mom51_solo_default
   collate: False


Inspecting the output
---------------------

======================  ======================
``mom.out``             Model output
``mom.err``             Model error
``bowl1.o${jobid}``     PBS (payu) output
``bowl1.e${jobid}``     PBS (payu) error
``archive/output000``   Model output files
``archive/restart000``  Restart (pickup) files
======================  ======================


Cleaning up
-----------

To clear ``work/`` and save PBS logs::

   payu sweep

Or to completely delete the experiment::

   payu sweep --hard

This wipes output, restarts, and logs! (``archive/$expt``)


Anatomy of an Experiment
========================

Control vs Laboratory
---------------------

Control path: ``${HOME}/mom/bowl1``
   User-configured (text) input

Laboratory: ``/short/$PROJECT/$USER/$MODEL/``
   Executables, data input, output, etc.

You "control" the laboratory externally


Laboratory overview
-------------------

============   ===============================
``archive``    Experiment output and restarts
``bin``        Model executables
``codebase``   Model Source code repository
``input``      Static input files
``work``       Ongoing (or failed) experiments
============   ===============================


A simple configuration
----------------------

We use the YAML format

.. code:: yaml

   model: mom6
   name: om4_gm_test

   queue: normal
   jobname: mom6_om4
   walltime: 20:00
   ncpus: 960
   mem: 1500GB

   exe: mom6_intel17
   input:
       - om4_grid
       - om4_atm

Most variables have "sensible" defaults


A more complex configuration
----------------------------

.. code:: yaml

   # PBS configuration
   queue: normal
   project: fp0
   walltime: 02:30:00
   jobname: om2_jra55
   ncpus: 1153
   mem: 2000GB

   #platform:
   #   nodesize: 28

   laboratory: /short/fp0/mxw900/cosima
   repeat: True

   collate:
       walltime: 4:00:00
       mem: 30GB
       ncpus: 4
       queue: express
       flags: -n4 -z -m -r

   # Model configuration
   model: access
   submodels:
       - name: coupler
         model: oasis
         input: oasis_025
         ncpus: 0

       - name: atmosphere
         model: matm
         exe: matm
         #input: jra55-0.8_025
         input: /short/v45/mxw900/cosima/nc64
         ncpus: 1

       - name: ocean
         model: mom
         exe: mom
         input:
             - mom
             # - iaf-sw21d
         ncpus: 960

       - name: ice
         model: cice
         exe: cice_nohalo
         input: cice
         ncpus: 192

   calendar:
       runtime:
           years: 0
           months: 0
           days: 30
       start:
           year: 1
           month: 1
           days: 1

   # Misc
   env:
       SCOREP_TOTAL_MEMORY: 1073741824
       SCOREP_MPI_ENABLE_GROUPS: all
       SCOREP_METRIC_RUSAGE: all

(Note: Slightly out of date!)


Configuring your experiment
---------------------------

=========   ===============   ==============
Config      Description       Default
=========   ===============   ==============
``model``   Model type        (required!)
``name``    Experiment name   Expt directory
``exe``     Executable        Set by driver
``input``   Model inputs      -
=========   ===============   ==============

Paths can be absolute or relative to the $LAB


Scheduler configuration
-----------------------

============   ==============    ============
Config         Description       Default
============   ==============    ============
``queue``      PBS Queue         ``normal``
``project``    SU Account        ``$PROJECT``
``jobname``    Queue job name    ``name``
``walltime``   Time request      (From PBS)
``ncpus``      CPU request       1
``mem``        RAM request       Max node mem
============   ==============    ============

``qsub_flags`` for everything else


.. CPU requests
   ------------

   Normally ``ncpus`` will increase itself to match the node, but more control is
   available.

   +----------+---------------+---------+
   | Config   | Description   | Default |
   +----------+---------------+---------+
   | platform                           |
   +----------+---------------+---------+
   | nodesize | CPUs per node | 16      |
   +----------+---------------+---------+
   | nodemem  | RAM per node  | 32      |
   +----------+---------------+---------+
   | ncpureq  | Override NCPU | (None)  |
   +----------+---------------+---------+

   npernode    CPUs per node     (

   ``jobfs``
   ``priority``
   ``join``       Merge stdout/err  ``n``


The work directory
------------------

Run the following to inspect (and test) your run:

.. code:: sh

   payu setup

This will create your ``work/`` directory in the lab


Inside the work directory
-------------------------

TODO


Feature overview
================

Multiple runs
-------------

To do multiple runs in sequence:

.. code::

   payu run -n 20

We save every output, and every 5th restart.

To change the rate::

   restart_freq: 1


Userscript support
------------------

Subcommands and scripts can be injected after key steps

.. code:: yaml

   userscripts:
      init: 'echo "some_data" > input.nml'
      setup: patch_inputs.py
      run: 'qsub postprocess.sh'

   postscript: cleanup.sh


Supported models
----------------

To see the supported models::

   payu list

But expect some atrophy...


Forking and sharing experiments
===============================

Creating a new experiment
-------------------------

Let's have some **FUN** and increase the timestep::

   cd ../mom   # Or whatever
   git clone bowl1 bowl2
   cd bowl2

We are in a hurry, so let's make ``dt_ocean`` in ``input.nml`` very large::

   f90nml -g ocean_model_nml -v dt_ocean=86400 input.nml > tmp.nml
   mv tmp.nml input.nml

(Or use a text editor)


Recording your progress
-----------------------

Track your changes to the run::

   git log

and responsible people *always* document their changes::

   git commit -am "Testing a large timestep"

But if you're lazy then payu will commit upon completion.

Let's run it!


FAILURE
-------

.. image:: img/angry.jpg

Your run crashed!!!


Inspecting failed jobs
----------------------

Failed jobs retain ``mom.out``, ``mom.err``, and ``work/``.

From ``mom.err``::

   FATAL from PE    2: ==>Error: time step instability detected for baroclinic gravity waves in ocean_model_mod

   forrtl: error (78): process killed (SIGTERM)

Errors are saved to ``archive/error_logs`` with PBS job IDs.

(Note: Error logs can get big fast!)


GitHub integration
------------------

You can sync your experiment on GitHub::

   payu ghsetup
   payu push

Visit your experiment in GitHub!

(Warning: Probably going to rename ``push``...)


Other GitHub features
---------------------

To disable the runlog::

   runlog: False

Or to save the jobs to an organization::

   organization: mxw900-raijin

There are few other features here, and someday may be documented!

Currently ``payu push`` is manual, but we could make it automatic.


Coupled Models
==============

ACCESS-OM2
----------

TODO


Troubleshooting
===============

"Please send me your job script"
--------------------------------

We don't have a "job script"...

... but, NCI is starting to understand, and CMS is prepared to run interference
